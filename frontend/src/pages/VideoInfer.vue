<template>
  <div class="video-infer">
    <div class="card">
      <h2>è§†é¢‘æ¨ç†</h2>
      
      <!-- æ¨¡å‹é€‰æ‹© -->
      <div class="form-group">
        <label>é€‰æ‹©æ¨¡å‹</label>
        <div class="select-with-refresh">
          <select v-model="selectedModel" :disabled="processing || loadingModels">
            <option value="">-- è¯·é€‰æ‹©æ¨¡å‹ --</option>
            <option v-for="model in models" :key="model.model_id" :value="model.model_id">
              {{ model.model_id }} ({{ model.classes?.length || 0 }} ç±»)
            </option>
          </select>
          <button type="button" @click="loadModels" class="refresh-btn" :disabled="loadingModels">
            <span v-if="loadingModels" class="loading-spinner"></span>
            {{ loadingModels ? 'åŠ è½½ä¸­...' : 'åˆ·æ–°' }}
          </button>
        </div>
      </div>
      
      <!-- ç½®ä¿¡åº¦é˜ˆå€¼ -->
      <div class="form-group">
        <label>ç½®ä¿¡åº¦é˜ˆå€¼: {{ confThreshold.toFixed(2) }}</label>
        <input 
          type="range" 
          v-model.number="confThreshold" 
          min="0.1" 
          max="0.9" 
          step="0.05"
          :disabled="processing"
        />
      </div>
      
      <!-- è§†é¢‘ä¸Šä¼ ï¼ˆéæ‘„åƒå¤´æ¨¡å¼æ˜¾ç¤ºï¼‰ -->
      <div v-if="processMode !== 'camera'" class="form-group">
        <label>ä¸Šä¼ è§†é¢‘</label>
        <input 
          type="file" 
          accept="video/*" 
          @change="handleVideoSelect" 
          ref="fileInputRef"
          :disabled="processing"
        />
        <small>æ”¯æŒ MP4ã€AVIã€MOV ç­‰å¸¸è§è§†é¢‘æ ¼å¼</small>
      </div>
      
      <!-- è§†é¢‘é¢„è§ˆï¼ˆéæ‘„åƒå¤´æ¨¡å¼æ˜¾ç¤ºï¼‰ -->
      <div v-if="videoPreview && processMode !== 'camera'" class="video-preview">
        <h4>åŸå§‹è§†é¢‘é¢„è§ˆ</h4>
        <video 
          ref="originalVideoRef"
          :src="videoPreview" 
          controls 
          class="preview-video"
        ></video>
      </div>
      
      <!-- å¤„ç†æ¨¡å¼é€‰æ‹© -->
      <div class="form-group">
        <label>å¤„ç†æ¨¡å¼</label>
        <div class="mode-select">
          <label class="radio-item">
            <input type="radio" v-model="processMode" value="full" :disabled="processing || isCameraActive" />
            <span>å®Œæ•´å¤„ç†</span>
            <small>å¤„ç†å®Œæ•´è§†é¢‘åè¿”å›ç»“æœï¼ˆé€‚åˆçŸ­è§†é¢‘ï¼‰</small>
          </label>
          <label class="radio-item">
            <input type="radio" v-model="processMode" value="stream" :disabled="processing || isCameraActive" />
            <span>æµå¼å¤„ç†</span>
            <small>å®æ—¶æ˜¾ç¤ºæ¯å¸§å¤„ç†ç»“æœï¼ˆé€‚åˆå®æ—¶æŸ¥çœ‹ï¼‰</small>
          </label>
          <label class="radio-item camera-mode">
            <input type="radio" v-model="processMode" value="camera" :disabled="processing || isCameraActive" />
            <span>æ‘„åƒå¤´å®æ—¶æ£€æµ‹</span>
            <small>ä½¿ç”¨æ‘„åƒå¤´è¿›è¡Œå®æ—¶ç›®æ ‡æ£€æµ‹</small>
          </label>
        </div>
      </div>
      
      <!-- å¼€å§‹å¤„ç†æŒ‰é’®ï¼ˆéæ‘„åƒå¤´æ¨¡å¼ï¼‰ -->
      <button 
        v-if="processMode !== 'camera'"
        @click="startProcessing" 
        :disabled="!selectedModel || !selectedVideo || processing"
      >
        <span v-if="processing" class="loading-spinner"></span>
        {{ processing ? 'å¤„ç†ä¸­...' : 'å¼€å§‹æ¨ç†' }}
      </button>
      
      <!-- åœæ­¢æŒ‰é’®ï¼ˆéæ‘„åƒå¤´æ¨¡å¼ï¼‰ -->
      <button 
        v-if="processing && processMode === 'stream'"
        @click="stopProcessing" 
        class="danger"
        style="margin-left: 0.5rem;"
      >
        åœæ­¢å¤„ç†
      </button>
      
      <!-- æ‘„åƒå¤´æ§åˆ¶æŒ‰é’® -->
      <div v-if="processMode === 'camera'" class="camera-controls">
        <button 
          v-if="!isCameraActive"
          @click="startCamera" 
          :disabled="!selectedModel"
          class="camera-btn start"
        >
          å¯åŠ¨æ‘„åƒå¤´
        </button>
        <button 
          v-else
          @click="stopCamera" 
          class="camera-btn stop danger"
        >
          åœæ­¢æ‘„åƒå¤´
        </button>
      </div>
      
      <!-- æ‘„åƒå¤´é”™è¯¯æç¤º -->
      <div v-if="cameraError" class="camera-error">
        {{ cameraError }}
      </div>
    </div>
    
    <!-- æ‘„åƒå¤´å®æ—¶æ£€æµ‹åŒºåŸŸ -->
    <div v-if="processMode === 'camera'" class="card camera-section">
      <h2>æ‘„åƒå¤´å®æ—¶æ£€æµ‹</h2>
      
      <!-- éšè—çš„videoå…ƒç´ ï¼ˆç”¨äºè·å–æ‘„åƒå¤´æµï¼‰ -->
      <video 
        ref="cameraVideoRef" 
        autoplay 
        playsinline 
        muted
        class="hidden-video"
      ></video>
      
      <!-- éšè—çš„canvasï¼ˆç”¨äºæ•è·å¸§ï¼‰ -->
      <canvas ref="cameraCanvasRef" class="hidden-canvas"></canvas>
      
      <!-- æ£€æµ‹ç»“æœcanvas -->
      <div class="camera-preview-container">
        <canvas 
          ref="detectionCanvasRef" 
          class="detection-canvas"
          :class="{ active: isCameraActive }"
        ></canvas>
        
        <div v-if="!isCameraActive && !cameraError" class="camera-placeholder">
          <div class="placeholder-icon">ğŸ“·</div>
          <p>ç‚¹å‡»"å¯åŠ¨æ‘„åƒå¤´"å¼€å§‹å®æ—¶æ£€æµ‹</p>
        </div>
      </div>
      
      <!-- æ‘„åƒå¤´ç»Ÿè®¡ä¿¡æ¯ -->
      <div v-if="isCameraActive" class="camera-stats">
        <div class="stat-item">
          <span class="stat-label">FPS</span>
          <span class="stat-value">{{ cameraStats.fps }}</span>
        </div>
        <div class="stat-item">
          <span class="stat-label">å·²å¤„ç†å¸§</span>
          <span class="stat-value">{{ cameraStats.framesProcessed }}</span>
        </div>
        <div class="stat-item">
          <span class="stat-label">æ€»æ£€æµ‹æ•°</span>
          <span class="stat-value">{{ cameraStats.totalDetections }}</span>
        </div>
      </div>
      
      <!-- å½“å‰æ£€æµ‹åˆ—è¡¨ -->
      <div v-if="isCameraActive && cameraDetections.length > 0" class="camera-detection-list">
        <h4>å½“å‰æ£€æµ‹ ({{ cameraDetections.length }})</h4>
        <div class="detection-items">
          <div v-for="(det, idx) in cameraDetections" :key="idx" class="detection-item">
            <span class="class-name" :style="{ color: getClassColor(det.class_id) }">
              {{ det.class_name }}
            </span>
            <span class="conf">{{ (det.conf * 100).toFixed(1) }}%</span>
          </div>
        </div>
      </div>
      
      <div v-if="isCameraActive && cameraDetections.length === 0" class="no-detections">
        æš‚æ— æ£€æµ‹åˆ°çš„ç›®æ ‡
      </div>
    </div>
    
    <!-- å¤„ç†è¿›åº¦ï¼ˆéæ‘„åƒå¤´æ¨¡å¼ï¼‰ -->
    <div v-if="processMode !== 'camera' && (processing || processComplete)" class="card">
      <h2>å¤„ç†çŠ¶æ€</h2>
      
      <!-- è¿›åº¦æ¡ -->
      <div v-if="videoInfo" class="progress-section">
        <div class="progress-info">
          <span>å¸§: {{ currentFrame }} / {{ videoInfo.total_frames }}</span>
          <span>{{ progressPercent.toFixed(1) }}%</span>
        </div>
        <div class="progress-bar">
          <div class="progress-fill" :style="{ width: progressPercent + '%' }"></div>
        </div>
      </div>
      
      <!-- ç»Ÿè®¡ä¿¡æ¯ -->
      <div v-if="stats" class="stats-section">
        <div class="stat-item">
          <span class="stat-label">æ€»æ£€æµ‹æ•°</span>
          <span class="stat-value">{{ stats.totalDetections }}</span>
        </div>
        <div class="stat-item">
          <span class="stat-label">æœ‰æ£€æµ‹çš„å¸§æ•°</span>
          <span class="stat-value">{{ stats.framesWithDetections }}</span>
        </div>
        <div class="stat-item">
          <span class="stat-label">å¤„ç†å¸§æ•°</span>
          <span class="stat-value">{{ currentFrame }}</span>
        </div>
      </div>
    </div>
    
    <!-- æµå¼å¤„ç†ç»“æœå±•ç¤ºï¼ˆä»…æµå¼æ¨¡å¼ï¼‰ -->
    <div v-if="processMode === 'stream' && !isCameraActive && (processing || processComplete)" class="card">
      <h2>å®æ—¶æ£€æµ‹ç»“æœ</h2>
      <div class="stream-result">
        <canvas ref="canvasRef" class="result-canvas"></canvas>
        <div v-if="currentDetections.length > 0" class="detection-list">
          <h4>å½“å‰å¸§æ£€æµ‹ ({{ currentDetections.length }})</h4>
          <div v-for="(det, idx) in currentDetections" :key="idx" class="detection-item">
            <span class="class-name" :style="{ color: getClassColor(det.class_id) }">
              {{ det.class_name }}
            </span>
            <span class="conf">{{ (det.conf * 100).toFixed(1) }}%</span>
          </div>
        </div>
      </div>
    </div>
    
    <!-- å®Œæ•´å¤„ç†ç»“æœ -->
    <div v-if="processMode === 'full' && processComplete && resultVideoUrl" class="card">
      <h2>å¤„ç†ç»“æœ</h2>
      <div class="result-section">
        <video 
          :src="resultVideoUrl" 
          controls 
          class="result-video"
        ></video>
        <div class="result-actions">
          <a :href="resultVideoUrl" download="result.mp4" class="download-btn">
            ä¸‹è½½å¤„ç†åçš„è§†é¢‘
          </a>
        </div>
      </div>
    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, computed, onUnmounted } from 'vue'
import { listModels } from '@/api/models'
import { videoInference, videoInferenceStream, inference, type VideoFrameData } from '@/api/infer'

const models = ref<any[]>([])
const loadingModels = ref(false)
const selectedModel = ref('')
const selectedVideo = ref<File | null>(null)
const videoPreview = ref<string | null>(null)
const confThreshold = ref(0.25)
const processMode = ref<'full' | 'stream' | 'camera'>('stream')

const processing = ref(false)
const processComplete = ref(false)
const currentFrame = ref(0)
const videoInfo = ref<{fps: number, width: number, height: number, total_frames: number} | null>(null)
const stats = ref<{totalDetections: number, framesWithDetections: number} | null>(null)
const currentDetections = ref<{class_id: number, class_name: string, conf: number, bbox: number[]}[]>([])
const resultVideoUrl = ref<string | null>(null)

const fileInputRef = ref<HTMLInputElement | null>(null)
const originalVideoRef = ref<HTMLVideoElement | null>(null)
const canvasRef = ref<HTMLCanvasElement | null>(null)

// æ‘„åƒå¤´ç›¸å…³çŠ¶æ€
const cameraVideoRef = ref<HTMLVideoElement | null>(null)
const cameraCanvasRef = ref<HTMLCanvasElement | null>(null)
const detectionCanvasRef = ref<HTMLCanvasElement | null>(null)
const isCameraActive = ref(false)
const cameraError = ref<string | null>(null)
const cameraStats = ref<{totalDetections: number, framesProcessed: number, fps: number}>({ 
  totalDetections: 0, 
  framesProcessed: 0,
  fps: 0 
})
const cameraDetections = ref<{class_id: number, class_name: string, conf: number, x1: number, y1: number, x2: number, y2: number}[]>([])

let mediaStream: MediaStream | null = null
let cameraAnimationId: number | null = null
let lastFrameTime = 0
let frameCount = 0
let fpsUpdateTime = 0

let stopRequested = false

const progressPercent = computed(() => {
  if (!videoInfo.value || videoInfo.value.total_frames === 0) return 0
  return (currentFrame.value / videoInfo.value.total_frames) * 100
})

const loadModels = async () => {
  loadingModels.value = true
  try {
    const result = await listModels()
    models.value = result.models
  } catch (error: any) {
    console.error('åŠ è½½æ¨¡å‹å¤±è´¥:', error)
    alert('åŠ è½½æ¨¡å‹å¤±è´¥: ' + (error.response?.data?.detail || error.message))
  } finally {
    loadingModels.value = false
  }
}

const handleVideoSelect = (event: Event) => {
  const target = event.target as HTMLInputElement
  const file = target.files?.[0]
  if (file) {
    selectedVideo.value = file
    videoPreview.value = URL.createObjectURL(file)
    // é‡ç½®çŠ¶æ€
    processComplete.value = false
    resultVideoUrl.value = null
    currentFrame.value = 0
    videoInfo.value = null
    stats.value = null
  }
}

const startProcessing = async () => {
  if (!selectedModel.value || !selectedVideo.value) return
  
  processing.value = true
  processComplete.value = false
  stopRequested = false
  currentFrame.value = 0
  stats.value = { totalDetections: 0, framesWithDetections: 0 }
  currentDetections.value = []
  resultVideoUrl.value = null
  
  try {
    if (processMode.value === 'full') {
      // å®Œæ•´å¤„ç†æ¨¡å¼
      const result = await videoInference(selectedModel.value, selectedVideo.value, confThreshold.value)
      
      if (result.error) {
        alert('å¤„ç†å¤±è´¥: ' + result.error)
        return
      }
      
      videoInfo.value = result.video_info
      currentFrame.value = result.video_info.processed_frames
      stats.value = {
        totalDetections: result.summary.total_detections,
        framesWithDetections: result.summary.frames_with_detections
      }
      
      // å°†base64è§†é¢‘è½¬ä¸ºURL
      const videoBlob = base64ToBlob(result.video_data, 'video/mp4')
      resultVideoUrl.value = URL.createObjectURL(videoBlob)
      
    } else {
      // æµå¼å¤„ç†æ¨¡å¼
      await videoInferenceStream(
        selectedModel.value,
        selectedVideo.value,
        confThreshold.value,
        (data: VideoFrameData) => {
          if (stopRequested) return
          
          if (data.type === 'info') {
            videoInfo.value = {
              fps: data.fps!,
              width: data.width!,
              height: data.height!,
              total_frames: data.total_frames!
            }
            // åˆå§‹åŒ–canvaså°ºå¯¸
            if (canvasRef.value) {
              canvasRef.value.width = data.width!
              canvasRef.value.height = data.height!
            }
          } else if (data.type === 'frame') {
            currentFrame.value = data.frame_number!
            currentDetections.value = data.detections || []
            
            // æ›´æ–°ç»Ÿè®¡
            if (stats.value) {
              stats.value.totalDetections += currentDetections.value.length
              if (currentDetections.value.length > 0) {
                stats.value.framesWithDetections++
              }
            }
            
            // ç»˜åˆ¶å¸§åˆ°canvas
            if (canvasRef.value && data.frame_data) {
              const ctx = canvasRef.value.getContext('2d')
              if (ctx) {
                const img = new Image()
                img.onload = () => {
                  ctx.drawImage(img, 0, 0)
                }
                img.src = 'data:image/jpeg;base64,' + data.frame_data
              }
            }
          } else if (data.type === 'complete') {
            currentFrame.value = data.processed_frames!
          }
        },
        (error) => {
          console.error('æµå¼å¤„ç†é”™è¯¯:', error)
          alert('å¤„ç†å¤±è´¥: ' + error.message)
        },
        () => {
          console.log('æµå¼å¤„ç†å®Œæˆ')
        }
      )
    }
    
    processComplete.value = true
    
  } catch (error: any) {
    console.error('å¤„ç†å¤±è´¥:', error)
    alert('å¤„ç†å¤±è´¥: ' + (error.message || 'æœªçŸ¥é”™è¯¯'))
  } finally {
    processing.value = false
  }
}

const stopProcessing = () => {
  stopRequested = true
  processing.value = false
}

const base64ToBlob = (base64: string, mimeType: string): Blob => {
  const byteCharacters = atob(base64)
  const byteNumbers = new Array(byteCharacters.length)
  for (let i = 0; i < byteCharacters.length; i++) {
    byteNumbers[i] = byteCharacters.charCodeAt(i)
  }
  const byteArray = new Uint8Array(byteNumbers)
  return new Blob([byteArray], { type: mimeType })
}

const getClassColor = (classId: number): string => {
  const colors = [
    '#00ff00', '#ff0000', '#0000ff', '#ffff00', '#ff00ff',
    '#00ffff', '#ff8000', '#8000ff', '#0080ff', '#ff0080'
  ]
  return colors[classId % colors.length]
}

// ============ æ‘„åƒå¤´ç›¸å…³å‡½æ•° ============

// å¯åŠ¨æ‘„åƒå¤´
const startCamera = async () => {
  if (!selectedModel.value) {
    alert('è¯·å…ˆé€‰æ‹©æ¨¡å‹')
    return
  }
  
  cameraError.value = null
  cameraStats.value = { totalDetections: 0, framesProcessed: 0, fps: 0 }
  cameraDetections.value = []
  
  try {
    // è¯·æ±‚æ‘„åƒå¤´æƒé™
    mediaStream = await navigator.mediaDevices.getUserMedia({
      video: {
        width: { ideal: 640 },
        height: { ideal: 480 },
        facingMode: 'environment' // ä¼˜å…ˆä½¿ç”¨åç½®æ‘„åƒå¤´
      },
      audio: false
    })
    
    // ç»‘å®šè§†é¢‘æµåˆ°videoå…ƒç´ 
    if (cameraVideoRef.value) {
      cameraVideoRef.value.srcObject = mediaStream
      await cameraVideoRef.value.play()
      
      // åˆå§‹åŒ–canvaså°ºå¯¸
      const videoWidth = cameraVideoRef.value.videoWidth
      const videoHeight = cameraVideoRef.value.videoHeight
      
      if (cameraCanvasRef.value) {
        cameraCanvasRef.value.width = videoWidth
        cameraCanvasRef.value.height = videoHeight
      }
      if (detectionCanvasRef.value) {
        detectionCanvasRef.value.width = videoWidth
        detectionCanvasRef.value.height = videoHeight
      }
      
      isCameraActive.value = true
      lastFrameTime = performance.now()
      fpsUpdateTime = lastFrameTime
      frameCount = 0
      
      // å¼€å§‹å¸§æ•è·å¾ªç¯
      captureLoop()
    }
  } catch (error: any) {
    console.error('å¯åŠ¨æ‘„åƒå¤´å¤±è´¥:', error)
    if (error.name === 'NotAllowedError') {
      cameraError.value = 'æ‘„åƒå¤´æƒé™è¢«æ‹’ç»ï¼Œè¯·å…è®¸è®¿é—®æ‘„åƒå¤´'
    } else if (error.name === 'NotFoundError') {
      cameraError.value = 'æœªæ£€æµ‹åˆ°æ‘„åƒå¤´è®¾å¤‡'
    } else if (error.name === 'NotReadableError') {
      cameraError.value = 'æ‘„åƒå¤´è¢«å…¶ä»–åº”ç”¨å ç”¨'
    } else {
      cameraError.value = 'å¯åŠ¨æ‘„åƒå¤´å¤±è´¥: ' + error.message
    }
  }
}

// åœæ­¢æ‘„åƒå¤´
const stopCamera = () => {
  isCameraActive.value = false
  
  // åœæ­¢åŠ¨ç”»å¾ªç¯
  if (cameraAnimationId !== null) {
    cancelAnimationFrame(cameraAnimationId)
    cameraAnimationId = null
  }
  
  // åœæ­¢æ‰€æœ‰è§†é¢‘è½¨é“
  if (mediaStream) {
    mediaStream.getTracks().forEach(track => track.stop())
    mediaStream = null
  }
  
  // æ¸…ç†videoå…ƒç´ 
  if (cameraVideoRef.value) {
    cameraVideoRef.value.srcObject = null
  }
  
  // æ¸…ç©ºæ£€æµ‹canvas
  if (detectionCanvasRef.value) {
    const ctx = detectionCanvasRef.value.getContext('2d')
    if (ctx) {
      ctx.clearRect(0, 0, detectionCanvasRef.value.width, detectionCanvasRef.value.height)
    }
  }
}

// å¸§æ•è·å¾ªç¯
let isProcessingFrame = false
const captureLoop = () => {
  if (!isCameraActive.value) return
  
  // å¦‚æœä¸Šä¸€å¸§è¿˜åœ¨å¤„ç†ä¸­ï¼Œè·³è¿‡è¿™ä¸€å¸§
  if (!isProcessingFrame) {
    captureAndProcessFrame()
  }
  
  cameraAnimationId = requestAnimationFrame(captureLoop)
}

// æ•è·å¸§å¹¶è¿›è¡Œæ¨ç†
const captureAndProcessFrame = async () => {
  if (!cameraVideoRef.value || !cameraCanvasRef.value || !detectionCanvasRef.value) return
  if (!isCameraActive.value) return
  
  isProcessingFrame = true
  
  try {
    const video = cameraVideoRef.value
    const captureCanvas = cameraCanvasRef.value
    const captureCtx = captureCanvas.getContext('2d')
    
    if (!captureCtx) return
    
    // ä»videoæ•è·å¸§åˆ°canvas
    captureCtx.drawImage(video, 0, 0, captureCanvas.width, captureCanvas.height)
    
    // å°†canvasè½¬ä¸ºBlob
    const blob = await new Promise<Blob | null>((resolve) => {
      captureCanvas.toBlob(resolve, 'image/jpeg', 0.8)
    })
    
    if (!blob) return
    
    // åˆ›å»ºFileå¯¹è±¡
    const file = new File([blob], 'frame.jpg', { type: 'image/jpeg' })
    
    // è°ƒç”¨æ¨ç†API
    const result = await inference(selectedModel.value, file)
    
    if (result.error) {
      console.error('æ¨ç†é”™è¯¯:', result.error)
      return
    }
    
    // æ›´æ–°æ£€æµ‹ç»“æœ
    cameraDetections.value = result.detections || []
    
    // æ›´æ–°ç»Ÿè®¡
    cameraStats.value.framesProcessed++
    cameraStats.value.totalDetections += cameraDetections.value.length
    
    // è®¡ç®—FPS
    frameCount++
    const now = performance.now()
    if (now - fpsUpdateTime >= 1000) {
      cameraStats.value.fps = Math.round(frameCount * 1000 / (now - fpsUpdateTime))
      frameCount = 0
      fpsUpdateTime = now
    }
    
    // ç»˜åˆ¶æ£€æµ‹ç»“æœ
    drawDetections(result.detections, result.image_width, result.image_height)
    
  } catch (error: any) {
    console.error('å¸§å¤„ç†é”™è¯¯:', error)
  } finally {
    isProcessingFrame = false
  }
}

// ç»˜åˆ¶æ£€æµ‹ç»“æœåˆ°canvas
const drawDetections = (
  detections: {class_id: number, class_name: string, conf: number, x1: number, y1: number, x2: number, y2: number}[],
  imageWidth: number,
  imageHeight: number
) => {
  if (!detectionCanvasRef.value || !cameraVideoRef.value) return
  
  const canvas = detectionCanvasRef.value
  const ctx = canvas.getContext('2d')
  if (!ctx) return
  
  // æ¸…ç©ºcanvas
  ctx.clearRect(0, 0, canvas.width, canvas.height)
  
  // ç»˜åˆ¶è§†é¢‘å¸§
  ctx.drawImage(cameraVideoRef.value, 0, 0, canvas.width, canvas.height)
  
  // è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
  const scaleX = canvas.width / imageWidth
  const scaleY = canvas.height / imageHeight
  
  // ç»˜åˆ¶æ£€æµ‹æ¡†
  detections.forEach((det) => {
    const x1 = det.x1 * scaleX
    const y1 = det.y1 * scaleY
    const x2 = det.x2 * scaleX
    const y2 = det.y2 * scaleY
    const width = x2 - x1
    const height = y2 - y1
    
    const color = getClassColor(det.class_id)
    
    // ç»˜åˆ¶è¾¹ç•Œæ¡†
    ctx.strokeStyle = color
    ctx.lineWidth = 3
    ctx.strokeRect(x1, y1, width, height)
    
    // ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
    const label = `${det.class_name}: ${(det.conf * 100).toFixed(1)}%`
    ctx.font = 'bold 14px Arial'
    const textMetrics = ctx.measureText(label)
    const textHeight = 18
    const padding = 4
    
    ctx.fillStyle = color
    ctx.fillRect(x1, y1 - textHeight - padding, textMetrics.width + padding * 2, textHeight + padding)
    
    // ç»˜åˆ¶æ ‡ç­¾æ–‡å­—
    ctx.fillStyle = '#ffffff'
    ctx.fillText(label, x1 + padding, y1 - padding - 2)
  })
}

// åˆå§‹åŒ–åŠ è½½æ¨¡å‹
loadModels()

// æ¸…ç†
onUnmounted(() => {
  // æ¸…ç†è§†é¢‘æ–‡ä»¶URL
  if (videoPreview.value) {
    URL.revokeObjectURL(videoPreview.value)
  }
  if (resultVideoUrl.value) {
    URL.revokeObjectURL(resultVideoUrl.value)
  }
  
  // æ¸…ç†æ‘„åƒå¤´èµ„æº
  if (isCameraActive.value) {
    stopCamera()
  }
  
  // ç¡®ä¿åŠ¨ç”»å¾ªç¯å·²åœæ­¢
  if (cameraAnimationId !== null) {
    cancelAnimationFrame(cameraAnimationId)
    cameraAnimationId = null
  }
  
  // ç¡®ä¿åª’ä½“æµå·²åœæ­¢
  if (mediaStream) {
    mediaStream.getTracks().forEach(track => track.stop())
    mediaStream = null
  }
})
</script>

<style scoped>
.video-infer {
  display: flex;
  flex-direction: column;
  gap: 1rem;
}

.select-with-refresh {
  display: flex;
  gap: 0.5rem;
}

.select-with-refresh select {
  flex: 1;
}

.refresh-btn {
  padding: 0.5rem 1rem;
  white-space: nowrap;
  display: inline-flex;
  align-items: center;
  gap: 0.25rem;
}

.video-preview {
  margin-top: 1rem;
}

.preview-video,
.result-video {
  width: 100%;
  max-width: 800px;
  border-radius: 4px;
  background: #000;
}

.mode-select {
  display: flex;
  flex-direction: column;
  gap: 0.75rem;
}

.radio-item {
  display: flex;
  align-items: flex-start;
  gap: 0.5rem;
  padding: 0.75rem;
  border: 1px solid #ddd;
  border-radius: 4px;
  cursor: pointer;
  transition: all 0.2s;
}

.radio-item:hover {
  border-color: #3498db;
}

.radio-item input[type="radio"] {
  margin-top: 0.25rem;
}

.radio-item span {
  font-weight: 500;
}

.radio-item small {
  display: block;
  color: #7f8c8d;
  margin-top: 0.25rem;
}

.progress-section {
  margin-bottom: 1rem;
}

.progress-info {
  display: flex;
  justify-content: space-between;
  margin-bottom: 0.5rem;
  font-size: 0.875rem;
  color: #7f8c8d;
}

.progress-bar {
  height: 8px;
  background: #ecf0f1;
  border-radius: 4px;
  overflow: hidden;
}

.progress-fill {
  height: 100%;
  background: linear-gradient(90deg, #3498db, #2ecc71);
  transition: width 0.3s;
}

.stats-section {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
  gap: 1rem;
}

.stat-item {
  padding: 1rem;
  background: #f8f9fa;
  border-radius: 4px;
  text-align: center;
}

.stat-label {
  display: block;
  font-size: 0.875rem;
  color: #7f8c8d;
  margin-bottom: 0.25rem;
}

.stat-value {
  display: block;
  font-size: 1.5rem;
  font-weight: 600;
  color: #2c3e50;
}

.stream-result {
  display: grid;
  grid-template-columns: 1fr 250px;
  gap: 1rem;
}

.result-canvas {
  width: 100%;
  height: auto;
  background: #000;
  border-radius: 4px;
}

.detection-list {
  max-height: 400px;
  overflow-y: auto;
}

.detection-list h4 {
  margin-bottom: 0.5rem;
  color: #2c3e50;
}

.detection-item {
  display: flex;
  justify-content: space-between;
  padding: 0.5rem;
  border-bottom: 1px solid #eee;
}

.class-name {
  font-weight: 500;
}

.conf {
  color: #7f8c8d;
}

.result-section {
  text-align: center;
}

.result-actions {
  margin-top: 1rem;
}

.download-btn {
  display: inline-block;
  padding: 0.75rem 1.5rem;
  background: #3498db;
  color: white;
  text-decoration: none;
  border-radius: 4px;
  transition: background 0.2s;
}

.download-btn:hover {
  background: #2980b9;
}

@media (max-width: 768px) {
  .stream-result {
    grid-template-columns: 1fr;
  }
  
  .detection-list {
    max-height: 200px;
  }
}

/* æ‘„åƒå¤´ç›¸å…³æ ·å¼ */
.camera-mode {
  border-color: #9b59b6;
}

.camera-mode:hover {
  border-color: #8e44ad;
}

.camera-controls {
  margin-top: 1rem;
}

.camera-btn {
  padding: 0.75rem 1.5rem;
  font-size: 1rem;
  border-radius: 4px;
  cursor: pointer;
  display: inline-flex;
  align-items: center;
  gap: 0.5rem;
}

.camera-btn.start {
  background: linear-gradient(135deg, #9b59b6, #8e44ad);
  color: white;
  border: none;
}

.camera-btn.start:hover:not(:disabled) {
  background: linear-gradient(135deg, #8e44ad, #7d3c98);
}

.camera-btn.start:disabled {
  opacity: 0.5;
  cursor: not-allowed;
}

.camera-btn.stop {
  background: #e74c3c;
  color: white;
  border: none;
}

.camera-btn.stop:hover {
  background: #c0392b;
}

.camera-error {
  margin-top: 1rem;
  padding: 0.75rem 1rem;
  background: #fdf2f2;
  border: 1px solid #f5c6cb;
  border-radius: 4px;
  color: #721c24;
}

.camera-section {
  background: linear-gradient(135deg, #f8f9fa, #fff);
}

.hidden-video,
.hidden-canvas {
  display: none;
}

.camera-preview-container {
  position: relative;
  width: 100%;
  max-width: 800px;
  margin: 1rem auto;
  background: #1e1e1e;
  border-radius: 8px;
  overflow: hidden;
  aspect-ratio: 4/3;
}

.detection-canvas {
  width: 100%;
  height: 100%;
  object-fit: contain;
}

.detection-canvas:not(.active) {
  display: none;
}

.camera-placeholder {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  color: #7f8c8d;
}

.placeholder-icon {
  font-size: 4rem;
  margin-bottom: 1rem;
}

.camera-stats {
  display: grid;
  grid-template-columns: repeat(3, 1fr);
  gap: 1rem;
  margin-top: 1rem;
}

.camera-stats .stat-item {
  padding: 0.75rem;
  background: linear-gradient(135deg, #9b59b6, #8e44ad);
  color: white;
  border-radius: 4px;
  text-align: center;
}

.camera-stats .stat-label {
  display: block;
  font-size: 0.75rem;
  opacity: 0.9;
  margin-bottom: 0.25rem;
}

.camera-stats .stat-value {
  display: block;
  font-size: 1.5rem;
  font-weight: 600;
}

.camera-detection-list {
  margin-top: 1rem;
  padding: 1rem;
  background: #f8f9fa;
  border-radius: 4px;
}

.camera-detection-list h4 {
  margin-bottom: 0.75rem;
  color: #2c3e50;
}

.detection-items {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(150px, 1fr));
  gap: 0.5rem;
}

.camera-detection-list .detection-item {
  display: flex;
  justify-content: space-between;
  padding: 0.5rem 0.75rem;
  background: white;
  border-radius: 4px;
  box-shadow: 0 1px 3px rgba(0,0,0,0.1);
}

.no-detections {
  margin-top: 1rem;
  padding: 1rem;
  text-align: center;
  color: #7f8c8d;
  background: #f8f9fa;
  border-radius: 4px;
}

@media (max-width: 768px) {
  .camera-stats {
    grid-template-columns: repeat(3, 1fr);
    gap: 0.5rem;
  }
  
  .camera-stats .stat-item {
    padding: 0.5rem;
  }
  
  .camera-stats .stat-value {
    font-size: 1.25rem;
  }
  
  .detection-items {
    grid-template-columns: 1fr 1fr;
  }
}
</style>
