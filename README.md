# ğŸš€ YOLO è®­ç»ƒå¹³å° | YOLO Training Platform

[English](#english) | [ä¸­æ–‡](#chinese)

---

<a name="chinese"></a>

## ä¸­æ–‡æ–‡æ¡£

### ç®€ä»‹

åŸºäº YOLOv8 + FastAPI + Vue3 çš„ç›®æ ‡æ£€æµ‹æ¨¡å‹è®­ç»ƒå¹³å°ã€‚æä¾›å®Œæ•´çš„æ•°æ®é›†ç®¡ç†ã€å¯è§†åŒ–æ ‡æ³¨ã€æ¨¡å‹è®­ç»ƒå’Œæ¨ç†åŠŸèƒ½ï¼Œæ”¯æŒ GPU åŠ é€Ÿè®­ç»ƒï¼Œå¼€ç®±å³ç”¨ã€‚

### åŠŸèƒ½ç‰¹æ€§

- âœ… **æ•°æ®é›†ä¸Šä¼ ä¸å‡†å¤‡** - æ”¯æŒ ZIP æ ¼å¼æ•°æ®é›†ä¸Šä¼ ï¼Œè‡ªåŠ¨è§£å‹å’Œç»„ç»‡
- âœ… **å¯è§†åŒ– BBox æ ‡æ³¨** - Canvas ç”»å¸ƒäº¤äº’å¼æ ‡æ³¨å·¥å…·
- âœ… **YOLOv8 æ¨¡å‹è®­ç»ƒ** - åå°å¼‚æ­¥è®­ç»ƒä»»åŠ¡ï¼Œæ”¯æŒ GPU åŠ é€Ÿ
- âœ… **å®æ—¶æ—¥å¿—æµ** - SSE å®æ—¶æ—¥å¿—æ¨é€ï¼Œæ–­çº¿è‡ªåŠ¨é™çº§åˆ°è½®è¯¢
- âœ… **æ¨¡å‹æ¨ç†** - æ”¯æŒå›¾ç‰‡å’Œè§†é¢‘æ¨ç†ï¼Œå¯è§†åŒ–æ£€æµ‹ç»“æœ
- âœ… **é«˜æ€§èƒ½è®­ç»ƒ** - è‡ªåŠ¨ Batch Sizeã€æ··åˆç²¾åº¦è®­ç»ƒã€ç£ç›˜ç¼“å­˜ä¼˜åŒ–
- âœ… **æ¨¡å‹ä¸Šä¼ ä¸å¯¼å‡º** - æ”¯æŒä¸Šä¼ å·²æœ‰æ¨¡å‹ï¼Œå¯¼å‡ºè®­ç»ƒåçš„æ¨¡å‹ä¸ºZIP
- âœ… **æ•°æ®é›†å¯¼å‡º** - æ”¯æŒå¯¼å‡ºæ ‡æ³¨å‰åçš„æ•°æ®é›†ï¼ˆYOLOæ ¼å¼ï¼‰
- âœ… **æ¨ç†ç»“æœå¯¼å‡º** - æ¨ç†ç»“æœè‡ªåŠ¨ç”ŸæˆUUIDï¼Œæ”¯æŒCSVå’Œå›¾ç‰‡å¯¼å‡º
- âœ… **è®­ç»ƒå›¾è¡¨ç”Ÿæˆ** - ä½¿ç”¨matplotlibç”Ÿæˆè®­ç»ƒæŒ‡æ ‡å¯è§†åŒ–å›¾è¡¨

### é¡¹ç›®ç»“æ„

```
yolo-platform/
â”œâ”€â”€ backend/              # FastAPI åç«¯
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/routes/  # è·¯ç”±å±‚
â”‚   â”‚   â”œâ”€â”€ services/    # ä¸šåŠ¡é€»è¾‘å±‚
â”‚   â”‚   â”œâ”€â”€ yolo/        # YOLO å°è£…
â”‚   â”‚   â”œâ”€â”€ core/        # é…ç½®
â”‚   â”‚   â””â”€â”€ main.py      # å…¥å£
â”‚   â”œâ”€â”€ data/            # æ•°æ®å­˜å‚¨
â”‚   â”œâ”€â”€ models/          # æ¨¡å‹æ³¨å†Œè¡¨
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/            # Vue3 å‰ç«¯
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/       # é¡µé¢
â”‚   â”‚   â”œâ”€â”€ components/  # ç»„ä»¶
â”‚   â”‚   â”œâ”€â”€ api/         # æ¥å£å°è£…
â”‚   â”‚   â””â”€â”€ store/       # Pinia çŠ¶æ€
â”‚   â””â”€â”€ package.json
â””â”€â”€ docker/              # Docker é…ç½®
    â”œâ”€â”€ backend/
    â”œâ”€â”€ frontend/
    â””â”€â”€ docker-compose.yml
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼ä¸€ï¼šæœ¬åœ°å¼€å‘ï¼ˆæ¨èç”¨äºå¼€å‘è°ƒè¯•ï¼‰

#### 1. åç«¯å¯åŠ¨

```bash
# 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n yoloapi python=3.10 -y
conda activate yoloapi

# 2. å®‰è£… PyTorch (RTX 5070 éœ€è¦ CUDA 12.1)
# æ–¹å¼ä¸€ï¼šä½¿ç”¨ pipï¼ˆæ¨èï¼‰
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# æ–¹å¼äºŒï¼šä½¿ç”¨ conda
# conda install pytorch torchvision pytorch-cuda=12.1 -c pytorch -c nvidia

# 3. å®‰è£…å…¶ä»–ä¾èµ–
cd backend
pip install -r requirements.txt

# 4. éªŒè¯ CUDAï¼ˆå¯é€‰ï¼‰
python -c "import torch; print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"}')"

# 5. å¯åŠ¨æœåŠ¡
cd ..
python -m uvicorn backend.src.main:app --reload --host 0.0.0.0 --port 8000
```

**æ³¨æ„**: RTX 5070 éœ€è¦å®‰è£…æ”¯æŒ CUDA 12.x çš„ PyTorchã€‚å¦‚æœä½¿ç”¨ CPU è®­ç»ƒï¼Œå¯ä»¥è·³è¿‡ PyTorch çš„ CUDA å®‰è£…ï¼Œç›´æ¥å®‰è£… `pip install torch torchvision`ã€‚

åç«¯å°†è¿è¡Œåœ¨ http://localhost:8000

#### 2. å‰ç«¯å¯åŠ¨

```bash
# 1. å®‰è£…ä¾èµ–
cd frontend
npm install

# 2. å¯åŠ¨å¼€å‘æœåŠ¡å™¨
npm run dev
```

å‰ç«¯å°†è¿è¡Œåœ¨ http://localhost:3000

---

### æ–¹å¼äºŒï¼šDocker éƒ¨ç½²ï¼ˆæ¨èç”¨äºç”Ÿäº§ç¯å¢ƒï¼‰

æœ¬é¡¹ç›®æä¾›äº†ç»Ÿä¸€çš„ Docker é•œåƒï¼Œå°†å‰ç«¯é¡µé¢ï¼ˆNginxï¼‰ä¸æ·±åº¦å­¦ä¹ åç«¯ï¼ˆPython/FastAPIï¼‰é›†æˆåœ¨åŒä¸€ä¸ªå®¹å™¨ä¸­ã€‚

#### é•œåƒæ‹‰å–

**å›½å†…ç”¨æˆ·ï¼ˆæ¨èä½¿ç”¨ CNB é•œåƒï¼‰ï¼š**

```bash
# ä» CNB é•œåƒä»“åº“æ‹‰å–ï¼ˆéœ€è¦æ›¿æ¢ä¸ºå®é™…çš„ CNB é•œåƒåœ°å€ï¼‰
docker pull docker.cnb.cool/xiaoclab/vegetable/yolo:latest
```

**æµ·å¤–ç”¨æˆ·ï¼ˆä½¿ç”¨ Docker Hubï¼‰ï¼š**

```bash
# ä» Docker Hub æ‹‰å–ï¼ˆéœ€è¦æ›¿æ¢ä¸ºå®é™…çš„ Docker Hub ç”¨æˆ·åï¼‰
docker pull xiaoclovemoney/yolo-training-platform:latest
```

#### å¯åŠ¨æ–¹å¼

##### æ–¹æ¡ˆ Aï¼šGPU æ¨¡å¼ï¼ˆè®­ç»ƒæ¨èï¼‰ğŸš€

å¦‚æœæ‚¨è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œå¼ºçƒˆå»ºè®®ä½¿ç”¨æ­¤å‘½ä»¤ä»¥å¯ç”¨ GPU åŠ é€Ÿã€‚
*å‰æï¼šå®¿ä¸»æœºéœ€å®‰è£… NVIDIA é©±åŠ¨åŠ NVIDIA Container Toolkitã€‚*

```bash
docker run -d \
  --name yolo-platform \
  -p 3000:80 \
  -p 8000:8000 \
  --gpus all \
  --shm-size=24gb \
  -e NVIDIA_VISIBLE_DEVICES=all \
  -e NVIDIA_DRIVER_CAPABILITIES=compute,utility \
  docker.cnb.cool/xiaoclab/vegetable/yolo:latest
```

##### æ–¹æ¡ˆ Bï¼šCPU æ¨¡å¼ï¼ˆä»…æ¨ç†/æµ‹è¯•ï¼‰

å¦‚æœæ‚¨æ²¡æœ‰ GPUï¼Œæˆ–è€…ä»…éœ€æµè§ˆç•Œé¢å’Œè¿›è¡Œç®€å•çš„ä»£ç è°ƒè¯•ã€‚

```bash
docker run -d \
  --name yolo-platform \
  -p 3000:80 \
  -p 8000:8000 \
  docker.cnb.cool/xiaoclab/vegetable/yolo:latest
```

#### è®¿é—®æœåŠ¡

- **Web ç•Œé¢**: æµè§ˆå™¨è®¿é—® `http://localhost:3000`
- **API æ–‡æ¡£**: æµè§ˆå™¨è®¿é—® `http://localhost:8000/docs`

#### Docker å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ |
| --- | --- |
| `-p 3000:80` | å°†å®¿ä¸»æœºçš„ 3000 ç«¯å£æ˜ å°„åˆ°å®¹å™¨çš„ Web æœåŠ¡ç«¯å£ã€‚ |
| `-p 8000:8000` | å°†å®¿ä¸»æœºçš„ 8000 ç«¯å£æ˜ å°„åˆ°å®¹å™¨çš„ API æœåŠ¡ç«¯å£ã€‚ |
| `--gpus all` | å…è®¸å®¹å™¨ä½¿ç”¨å®¿ä¸»æœºä¸Šçš„æ‰€æœ‰ GPUã€‚ |
| `--shm-size=24gb` | **é‡è¦**ï¼šå¢åŠ å…±äº«å†…å­˜å¤§å°ã€‚YOLO/PyTorch åœ¨å¤„ç†å¤šè¿›ç¨‹æ•°æ®åŠ è½½æ—¶éœ€è¦è¾ƒå¤§çš„å…±äº«å†…å­˜ï¼Œå¦åˆ™å¯èƒ½æŠ¥é”™ã€‚ |
| `-e NVIDIA_VISIBLE_DEVICES=all` | æ˜¾å¼æŒ‡å®šå®¹å™¨å¯è§çš„ GPU è®¾å¤‡ã€‚ |
| `-e NVIDIA_DRIVER_CAPABILITIES...` | èµ‹äºˆå®¹å™¨è°ƒç”¨å®¿ä¸»æœº GPU é©±åŠ¨è®¡ç®—èƒ½åŠ›çš„æƒé™ã€‚ |

---

## ğŸ“– ä½¿ç”¨æŒ‡å—

### å®Œæ•´æ“ä½œæµç¨‹

#### 1ï¸âƒ£ ä¸Šä¼ æ•°æ®é›†ï¼ˆå¿…é¡»ç¬¬ä¸€æ­¥ï¼‰

è®¿é—® http://localhost:3000/datasets

1. ç‚¹å‡»"é€‰æ‹© ZIP æ–‡ä»¶"ï¼Œé€‰æ‹©åŒ…å«å›¾ç‰‡çš„ zip æ–‡ä»¶
2. ç‚¹å‡»"ä¸Šä¼ "
3. **é‡è¦**ï¼šä¸Šä¼ æˆåŠŸåï¼Œç‚¹å‡»"å‡†å¤‡æ•°æ®é›†"æŒ‰é’®
4. ç­‰å¾…å‡†å¤‡å®Œæˆï¼ŒçŠ¶æ€å˜ä¸º `prepared`

**æ•°æ®é›† ZIP æ–‡ä»¶è¦æ±‚ï¼š**

**æ–¹å¼ä¸€ï¼šYOLO æ ¼å¼ï¼ˆæ¨èï¼‰**
```
dataset.zip
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ img1.jpg
â”‚   â”‚   â””â”€â”€ img2.jpg
â”‚   â””â”€â”€ val/
â”‚       â””â”€â”€ img3.jpg
â””â”€â”€ labels/
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ img1.txt
    â”‚   â””â”€â”€ img2.txt
    â””â”€â”€ val/
        â””â”€â”€ img3.txt
```

**æ–¹å¼äºŒï¼šä»…å›¾ç‰‡ï¼ˆéœ€è¦æ ‡æ³¨ï¼‰**
```
dataset.zip
â”œâ”€â”€ img1.jpg
â”œâ”€â”€ img2.jpg
â””â”€â”€ img3.jpg
```

#### 2ï¸âƒ£ åˆ›å»ºæ ‡æ³¨ä»»åŠ¡

è®¿é—® http://localhost:3000/annotate

1. å¤åˆ¶æ•°æ®é›†é¡µé¢ä¸­å·²å‡†å¤‡å¥½çš„æ•°æ®é›† IDï¼ˆå¦‚ `ds_20260115_212121`ï¼‰
2. ç²˜è´´åˆ°"æ•°æ®é›†ID"è¾“å…¥æ¡†
3. è¾“å…¥ç±»åˆ«ï¼ˆå¦‚ `person,car,dog`ï¼‰
4. ç‚¹å‡»"åˆ›å»ºä»»åŠ¡"
5. åœ¨ç”»å¸ƒä¸Šæ‹–åŠ¨é¼ æ ‡ç»˜åˆ¶è¾¹ç•Œæ¡†
6. å³ä¾§é€‰æ‹©ç±»åˆ«å¹¶æŸ¥çœ‹å½“å‰æ ‡æ³¨
7. ç‚¹å‡»"ä¿å­˜"ä¿å­˜å½“å‰å›¾ç‰‡æ ‡æ³¨
8. ä½¿ç”¨"ä¸Šä¸€å¼ /ä¸‹ä¸€å¼ "åˆ‡æ¢å›¾ç‰‡
9. å®Œæˆåç‚¹å‡»"å¯¼å‡ºYOLO"ç”Ÿæˆ YOLO æ ¼å¼æ ‡ç­¾

**âš ï¸ å¸¸è§é”™è¯¯**ï¼š
- å¦‚æœæç¤º "æ•°æ®é›†ä¸­æœªæ‰¾åˆ°å›¾ç‰‡ç›®å½•"ï¼Œè¯´æ˜æ²¡æœ‰æ‰§è¡Œ prepare æ“ä½œ
- å¿…é¡»å…ˆåœ¨æ•°æ®é›†é¡µé¢å®Œæˆ prepareï¼Œå†æ¥æ ‡æ³¨é¡µé¢åˆ›å»ºä»»åŠ¡

#### 3ï¸âƒ£ æ¨¡å‹è®­ç»ƒ

è®¿é—® http://localhost:3000/train

1. è¾“å…¥å·²å‡†å¤‡å¥½çš„æ•°æ®é›† ID
2. é€‰æ‹©æ¨¡å‹ï¼ˆå»ºè®®é¦–æ¬¡æµ‹è¯•ç”¨ YOLOv8nï¼‰
3. è®¾ç½®å‚æ•°ï¼ˆå»ºè®®é¦–æ¬¡æµ‹è¯•ï¼šepochs=2, batch=8ï¼‰
4. ç‚¹å‡»"å¼€å§‹è®­ç»ƒ"
5. å®æ—¶æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
6. è®­ç»ƒå®Œæˆååœ¨ä»»åŠ¡åˆ—è¡¨æŸ¥çœ‹æ¨¡å‹ ID

#### 4ï¸âƒ£ æ¨¡å‹æ¨ç†

è®¿é—® http://localhost:3000/infer

1. ç‚¹å‡»"åˆ·æ–°æ¨¡å‹"åŠ è½½å·²è®­ç»ƒæ¨¡å‹
2. é€‰æ‹©ä¸€ä¸ªæ¨¡å‹
3. ä¸Šä¼ æµ‹è¯•å›¾ç‰‡
4. ç‚¹å‡»"å¼€å§‹æ¨ç†"
5. æŸ¥çœ‹æ£€æµ‹ç»“æœå’Œå¯è§†åŒ–

---

## âš¡ è®­ç»ƒæ€§èƒ½ä¼˜åŒ–

ç³»ç»Ÿä½¿ç”¨**é«˜æ€§èƒ½æ¨¡å¼**ï¼Œæœ€å¤§åŒ– GPU åˆ©ç”¨ç‡ï¼ŒåŒæ—¶é¿å…å†…å­˜æº¢å‡ºã€‚

### æ ¸å¿ƒä¼˜åŒ–

| å‚æ•° | è®¾ç½® | è¯´æ˜ |
|------|------|------|
| Batch Size | è‡ªåŠ¨ | æ ¹æ®æ˜¾å­˜å¤§å°è‡ªåŠ¨è®¡ç®—æœ€ä½³å€¼ |
| Workers | 8 | å¹³è¡¡æ•°æ®åŠ è½½é€Ÿåº¦å’Œå†…å­˜ä½¿ç”¨ |
| Cache | disk | ç£ç›˜ç¼“å­˜ï¼ŒåŠ é€Ÿæ•°æ®åŠ è½½ï¼Œä¸å å†…å­˜ |
| AMP | å¯ç”¨ | æ··åˆç²¾åº¦è®­ç»ƒï¼ŒèŠ‚çœæ˜¾å­˜ï¼Œæå‡é€Ÿåº¦ |

### è‡ªåŠ¨ Batch Size

ç³»ç»Ÿä¼šæ ¹æ® GPU æ˜¾å­˜è‡ªåŠ¨è®¡ç®—æœ€ä½³ batch sizeï¼š

| æ˜¾å­˜ | å›¾ç‰‡å°ºå¯¸ 416 | å›¾ç‰‡å°ºå¯¸ 640 | å›¾ç‰‡å°ºå¯¸ 1024 |
|------|-------------|-------------|---------------|
| 20GB+ (4090) | 64 | 32 | 16 |
| 10-20GB (5070/4080) | 48 | 24 | 12 |
| <10GB | 32 | 16 | 8 |

### GPU åˆ©ç”¨ç‡æå‡

- **ä¼˜åŒ–å‰**ï¼š~70%
- **ä¼˜åŒ–å**ï¼š~90-95%

è¯¦ç»†ä¼˜åŒ–è¯´æ˜è¯·å‚è€ƒ [TRAINING_OPTIMIZATION.md](TRAINING_OPTIMIZATION.md)

---

## ğŸ”§ API æµ‹è¯•

### 1. ä¸Šä¼ æ•°æ®é›†

```bash
curl -X POST http://localhost:8000/datasets/upload \
  -F "file=@your_dataset.zip"
```

è¿”å›:
```json
{
  "dataset_id": "ds_20240115_123456",
  "filename": "your_dataset.zip",
  "size": 12345678
}
```

### 2. å‡†å¤‡æ•°æ®é›†

```bash
curl -X POST http://localhost:8000/datasets/ds_20240115_123456/prepare \
  -H "Content-Type: application/json" \
  -d '{"split_ratio": {"train": 0.8, "val": 0.2}, "classes": ["person", "car"]}'
```

### 3. åˆ›å»ºè®­ç»ƒä»»åŠ¡

```bash
curl -X POST http://localhost:8000/train/jobs \
  -H "Content-Type: application/json" \
  -d '{
    "dataset_id": "ds_20240115_123456",
    "version": "v1",
    "model_name": "yolov8n.pt",
    "epochs": 10,
    "imgsz": 640,
    "batch": 16
  }'
```

è¿”å›:
```json
{
  "job_id": "job_20240115_123456",
  "status": "running"
}
```

### 4. æŸ¥çœ‹æ—¥å¿— (SSE)

```bash
curl -N http://localhost:8000/logs/stream?job_id=job_20240115_123456
```

### 5. æ¨ç†

```bash
curl -X POST http://localhost:8000/infer/model_20240115_123456 \
  -F "file=@test_image.jpg"
```

---

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

**åç«¯:**
- FastAPI - Web æ¡†æ¶
- Ultralytics YOLOv8 - ç›®æ ‡æ£€æµ‹
- Uvicorn - ASGI æœåŠ¡å™¨
- Pydantic - æ•°æ®éªŒè¯
- PyTorch - æ·±åº¦å­¦ä¹ æ¡†æ¶

**å‰ç«¯:**
- Vue 3 - å‰ç«¯æ¡†æ¶
- Vite - æ„å»ºå·¥å…·
- Vue Router - è·¯ç”±
- Pinia - çŠ¶æ€ç®¡ç†
- Axios - HTTP å®¢æˆ·ç«¯
- TypeScript - ç±»å‹å®‰å…¨

**éƒ¨ç½²:**
- Docker - å®¹å™¨åŒ–
- Nginx - Web æœåŠ¡å™¨
- Supervisor - è¿›ç¨‹ç®¡ç†

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ•°æ®é›†æ ¼å¼**: æ”¯æŒä¸¤ç§è¾“å…¥
   - YOLO æ ¼å¼: `images/` å’Œ `labels/` ç›®å½•
   - çº¯å›¾ç‰‡: ä»… `images/` ç›®å½•ï¼ˆéœ€è¦åç»­æ ‡æ³¨ï¼‰

2. **è®­ç»ƒæ—¥å¿—**: ä¼˜å…ˆä½¿ç”¨ SSE æµï¼Œæ–­çº¿è‡ªåŠ¨åˆ‡æ¢åˆ°è½®è¯¢æ¨¡å¼

3. **æ¨¡å‹å­˜å‚¨**: è®­ç»ƒå®Œæˆçš„æ¨¡å‹ä¿å­˜åœ¨ `backend/models/registry/`

4. **ç«¯å£é…ç½®**: 
   - åç«¯: 8000
   - å‰ç«¯: 3000

5. **GPU è®­ç»ƒ**: éœ€è¦ NVIDIA GPU å’Œ CUDA æ”¯æŒï¼Œå»ºè®®ä½¿ç”¨ GPU æ¨¡å¼è¿›è¡Œè®­ç»ƒ

---

## ğŸ” æ•…éšœæ’æŸ¥

### è®­ç»ƒä»»åŠ¡ä¸å¯åŠ¨
- æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å·²å‡†å¤‡ (status: "prepared")
- ç¡®è®¤ `data.yaml` å­˜åœ¨äºæ•°æ®é›†ç‰ˆæœ¬ç›®å½•
- æ£€æŸ¥ GPU æ˜¯å¦å¯ç”¨ï¼ˆå¦‚æœä½¿ç”¨ GPU æ¨¡å¼ï¼‰

### æ—¥å¿—ä¸æ˜¾ç¤º
- æ£€æŸ¥æµè§ˆå™¨æ§åˆ¶å° SSE è¿æ¥çŠ¶æ€
- ç¡®è®¤è®­ç»ƒè¿›ç¨‹å·²å¯åŠ¨å¹¶å†™å…¥æ—¥å¿—æ–‡ä»¶
- ç³»ç»Ÿä¼šè‡ªåŠ¨é™çº§åˆ°è½®è¯¢æ¨¡å¼

### æ¨ç†å¤±è´¥
- ç¡®è®¤æ¨¡å‹æƒé‡æ–‡ä»¶ `best.pt` å­˜åœ¨
- æ£€æŸ¥ä¸Šä¼ å›¾ç‰‡æ ¼å¼æ˜¯å¦æ”¯æŒ
- ç¡®è®¤æ¨¡å‹å·²è®­ç»ƒå®Œæˆ

### åˆ›å»ºæ ‡æ³¨ä»»åŠ¡å¤±è´¥
**é”™è¯¯ä¿¡æ¯**ï¼š`æ•°æ®é›† xxx ä¸­æœªæ‰¾åˆ°å›¾ç‰‡ç›®å½•`

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. å›åˆ°æ•°æ®é›†é¡µé¢
2. æ‰¾åˆ°å¯¹åº”çš„æ•°æ®é›†
3. ç¡®è®¤çŠ¶æ€æ˜¯ `prepared` è€Œä¸æ˜¯ `uploaded`
4. å¦‚æœæ˜¯ `uploaded`ï¼Œç‚¹å‡»è¯¥æ•°æ®é›†çš„"å‡†å¤‡æ•°æ®é›†"æŒ‰é’®
5. ç­‰å¾…å‡†å¤‡å®Œæˆåå†åˆ›å»ºæ ‡æ³¨ä»»åŠ¡

### GPU ç›¸å…³é—®é¢˜
- **CUDA out of memory**: å‡å° batch size æˆ–å›¾ç‰‡å°ºå¯¸
- **GPU åˆ©ç”¨ç‡ä½**: æ£€æŸ¥æ•°æ®é›†å¤§å°ï¼Œç¡®ä¿ä½¿ç”¨ disk ç¼“å­˜
- **GPU ä¸å¯ç”¨**: ç¡®è®¤å®‰è£…äº† NVIDIA é©±åŠ¨å’Œ NVIDIA Container Toolkit

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [å¿«é€Ÿå¼€å§‹æŒ‡å—](QUICK_START.md) - è¯¦ç»†çš„å¿«é€Ÿå¼€å§‹æ•™ç¨‹
- [è®­ç»ƒä¼˜åŒ–è¯´æ˜](TRAINING_OPTIMIZATION.md) - è®­ç»ƒæ€§èƒ½ä¼˜åŒ–è¯¦è§£

---

## ğŸ“„ License

MIT

---

<a name="english"></a>

## English Documentation

### Introduction

A YOLO training platform based on YOLOv8 + FastAPI + Vue3. Provides complete dataset management, visual annotation, model training, and inference capabilities, with GPU acceleration support, ready to use out of the box.

### Features

- âœ… **Dataset Upload & Preparation** - Support ZIP format dataset upload with automatic extraction and organization
- âœ… **Visual BBox Annotation** - Interactive Canvas annotation tool
- âœ… **YOLOv8 Model Training** - Background asynchronous training tasks with GPU acceleration
- âœ… **Real-time Log Streaming** - SSE real-time log push with automatic fallback to polling
- âœ… **Model Inference** - Support image and video inference with visualization
- âœ… **High-performance Training** - Auto Batch Size, mixed precision training, disk cache optimization
- âœ… **Model Upload & Export** - Upload existing models, export trained models as ZIP
- âœ… **Dataset Export** - Export datasets before/after annotation (YOLO format)
- âœ… **Inference Results Export** - Auto-generate UUID for inference results, support CSV and image export
- âœ… **Training Charts Generation** - Generate training metrics visualization charts using matplotlib

### Project Structure

```
yolo-platform/
â”œâ”€â”€ backend/              # FastAPI Backend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/routes/  # Route layer
â”‚   â”‚   â”œâ”€â”€ services/    # Business logic layer
â”‚   â”‚   â”œâ”€â”€ yolo/        # YOLO wrapper
â”‚   â”‚   â”œâ”€â”€ core/        # Configuration
â”‚   â”‚   â””â”€â”€ main.py      # Entry point
â”‚   â”œâ”€â”€ data/            # Data storage
â”‚   â”œâ”€â”€ models/          # Model registry
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/            # Vue3 Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/       # Pages
â”‚   â”‚   â”œâ”€â”€ components/  # Components
â”‚   â”‚   â”œâ”€â”€ api/         # API wrapper
â”‚   â”‚   â””â”€â”€ store/       # Pinia state
â”‚   â””â”€â”€ package.json
â””â”€â”€ docker/              # Docker configuration
    â”œâ”€â”€ backend/
    â”œâ”€â”€ frontend/
    â””â”€â”€ docker-compose.yml
```

---

## ğŸš€ Quick Start

### Option 1: Local Development (Recommended for Development)

#### 1. Backend Setup

```bash
# 1. Create virtual environment
conda create -n yoloapi python=3.10 -y
conda activate yoloapi

# 2. Install PyTorch (RTX 5070 requires CUDA 12.1)
# Option 1: Using pip (Recommended)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# Option 2: Using conda
# conda install pytorch torchvision pytorch-cuda=12.1 -c pytorch -c nvidia

# 3. Install other dependencies
cd backend
pip install -r requirements.txt

# 4. Verify CUDA (Optional)
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"}')"

# 5. Start service
cd ..
python -m uvicorn backend.src.main:app --reload --host 0.0.0.0 --port 8000
```

**Note**: RTX 5070 requires PyTorch with CUDA 12.x support. For CPU training, skip CUDA installation and install `pip install torch torchvision` directly.

Backend will run at http://localhost:8000

#### 2. Frontend Setup

```bash
# 1. Install dependencies
cd frontend
npm install

# 2. Start development server
npm run dev
```

Frontend will run at http://localhost:3000

---

### Option 2: Docker Deployment (Recommended for Production)

This project provides a unified Docker image that integrates the frontend (Nginx) and backend (Python/FastAPI) into a single container.

#### Pull Image

**For Chinese Users (Recommended: CNB Registry):**

```bash
# Pull from CNB registry (replace with actual CNB image address)
docker pull <cnb-registry>/<repo-name>/yolo:latest
```

**For Overseas Users (Docker Hub):**

```bash
# Pull from Docker Hub (replace with actual Docker Hub username)
docker pull xiaoclovemoney/yolo-training-platform:latest
```

#### Startup Methods

##### Option A: GPU Mode (Recommended for Training) ğŸš€

If you are training models, it is strongly recommended to use this command to enable GPU acceleration.
*Prerequisite: Host machine must have NVIDIA drivers and NVIDIA Container Toolkit installed.*

```bash
docker run -d \
  --name yolo-platform \
  -p 3000:80 \
  -p 8000:8000 \
  --gpus all \
  --shm-size=24gb \
  -e NVIDIA_VISIBLE_DEVICES=all \
  -e NVIDIA_DRIVER_CAPABILITIES=compute,utility \
  docker.cnb.cool/xiaoclab/vegetable/yolo:latest
```

##### Option B: CPU Mode (Inference/Testing Only)

If you don't have a GPU, or only need to browse the interface and perform simple debugging.

```bash
docker run -d \
  --name yolo-platform \
  -p 3000:80 \
  -p 8000:8000 \
  docker.cnb.cool/xiaoclab/vegetable/yolo:latest
```

#### Access Services

- **Web UI**: Open browser and visit `http://localhost:3000`
- **API Docs**: Visit `http://localhost:8000/docs`

#### Docker Parameter Explanation

| Flag | Description |
| --- | --- |
| `-p 3000:80` | Maps host port 3000 to container port 80 (Frontend UI). |
| `-p 8000:8000` | Maps host port 8000 to container port 8000 (Backend API). |
| `--gpus all` | Enables access to all available NVIDIA GPUs. |
| `--shm-size=24gb` | **Important**: Increases shared memory to prevent PyTorch `DataLoader` crashes. |
| `-e NVIDIA_VISIBLE_DEVICES=all` | Explicitly exposes all GPU devices to the container. |
| `-e NVIDIA_DRIVER_CAPABILITIES...` | Ensures the container can use compute and utility drivers. |

---

## ğŸ“– User Guide

### Complete Workflow

#### 1ï¸âƒ£ Upload Dataset (Required First Step)

Visit http://localhost:3000/datasets

1. Click "Select ZIP File" and choose a zip file containing images
2. Click "Upload"
3. **Important**: After upload succeeds, click "Prepare Dataset" button
4. Wait for preparation to complete, status changes to `prepared`

**Dataset ZIP File Requirements:**

**Option 1: YOLO Format (Recommended)**
```
dataset.zip
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ img1.jpg
â”‚   â”‚   â””â”€â”€ img2.jpg
â”‚   â””â”€â”€ val/
â”‚       â””â”€â”€ img3.jpg
â””â”€â”€ labels/
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ img1.txt
    â”‚   â””â”€â”€ img2.txt
    â””â”€â”€ val/
        â””â”€â”€ img3.txt
```

**Option 2: Images Only (Requires Annotation)**
```
dataset.zip
â”œâ”€â”€ img1.jpg
â”œâ”€â”€ img2.jpg
â””â”€â”€ img3.jpg
```

#### 2ï¸âƒ£ Create Annotation Task

Visit http://localhost:3000/annotate

1. Copy the prepared dataset ID from the dataset page (e.g., `ds_20260115_212121`)
2. Paste into "Dataset ID" input field
3. Enter classes (e.g., `person,car,dog`)
4. Click "Create Task"
5. Draw bounding boxes on canvas by dragging mouse
6. Select class on the right and view current annotations
7. Click "Save" to save current image annotation
8. Use "Previous/Next" to switch images
9. After completion, click "Export YOLO" to generate YOLO format labels

**âš ï¸ Common Error**:
- If prompted "Image directory not found in dataset", it means prepare operation was not executed
- Must complete prepare on dataset page first, then create annotation task

#### 3ï¸âƒ£ Model Training

Visit http://localhost:3000/train

1. Enter prepared dataset ID
2. Select model (recommend YOLOv8n for first test)
3. Set parameters (recommend for first test: epochs=2, batch=8)
4. Click "Start Training"
5. View real-time training logs
6. After training completes, check model ID in task list

#### 4ï¸âƒ£ Model Inference

Visit http://localhost:3000/infer

1. Click "Refresh Models" to load trained models
2. Select a model
3. Upload test image
4. Click "Start Inference"
5. View detection results and visualization

---

## âš¡ Training Performance Optimization

The system uses **high-performance mode** to maximize GPU utilization while avoiding memory overflow.

### Core Optimizations

| Parameter | Setting | Description |
|------|------|------|
| Batch Size | Auto | Automatically calculates optimal value based on VRAM |
| Workers | 8 | Balances data loading speed and memory usage |
| Cache | disk | Disk cache, accelerates data loading without using memory |
| AMP | Enabled | Mixed precision training, saves VRAM, improves speed |

### Auto Batch Size

The system automatically calculates optimal batch size based on GPU VRAM:

| VRAM | Image Size 416 | Image Size 640 | Image Size 1024 |
|------|-------------|-------------|---------------|
| 20GB+ (4090) | 64 | 32 | 16 |
| 10-20GB (5070/4080) | 48 | 24 | 12 |
| <10GB | 32 | 16 | 8 |

### GPU Utilization Improvement

- **Before optimization**: ~70%
- **After optimization**: ~90-95%

For detailed optimization instructions, see [TRAINING_OPTIMIZATION.md](TRAINING_OPTIMIZATION.md)

---

## ğŸ”§ API Testing

### 1. Upload Dataset

```bash
curl -X POST http://localhost:8000/datasets/upload \
  -F "file=@your_dataset.zip"
```

Response:
```json
{
  "dataset_id": "ds_20240115_123456",
  "filename": "your_dataset.zip",
  "size": 12345678
}
```

### 2. Prepare Dataset

```bash
curl -X POST http://localhost:8000/datasets/ds_20240115_123456/prepare \
  -H "Content-Type: application/json" \
  -d '{"split_ratio": {"train": 0.8, "val": 0.2}, "classes": ["person", "car"]}'
```

### 3. Create Training Job

```bash
curl -X POST http://localhost:8000/train/jobs \
  -H "Content-Type: application/json" \
  -d '{
    "dataset_id": "ds_20240115_123456",
    "version": "v1",
    "model_name": "yolov8n.pt",
    "epochs": 10,
    "imgsz": 640,
    "batch": 16
  }'
```

Response:
```json
{
  "job_id": "job_20240115_123456",
  "status": "running"
}
```

### 4. View Logs (SSE)

```bash
curl -N http://localhost:8000/logs/stream?job_id=job_20240115_123456
```

### 5. Inference

```bash
curl -X POST http://localhost:8000/infer/model_20240115_123456 \
  -F "file=@test_image.jpg"
```

---

## ğŸ› ï¸ Tech Stack

**Backend:**
- FastAPI - Web framework
- Ultralytics YOLOv8 - Object detection
- Uvicorn - ASGI server
- Pydantic - Data validation
- PyTorch - Deep learning framework

**Frontend:**
- Vue 3 - Frontend framework
- Vite - Build tool
- Vue Router - Routing
- Pinia - State management
- Axios - HTTP client
- TypeScript - Type safety

**Deployment:**
- Docker - Containerization
- Nginx - Web server
- Supervisor - Process management

---

## âš ï¸ Notes

1. **Dataset Format**: Supports two input types
   - YOLO format: `images/` and `labels/` directories
   - Images only: Only `images/` directory (requires subsequent annotation)

2. **Training Logs**: Prioritizes SSE streaming, automatically falls back to polling mode on disconnection

3. **Model Storage**: Trained models are saved in `backend/models/registry/`

4. **Port Configuration**: 
   - Backend: 8000
   - Frontend: 3000

5. **GPU Training**: Requires NVIDIA GPU and CUDA support, recommend using GPU mode for training

---

## ğŸ” Troubleshooting

### Training Job Not Starting
- Check if dataset is prepared (status: "prepared")
- Confirm `data.yaml` exists in dataset version directory
- Check if GPU is available (if using GPU mode)

### Logs Not Displaying
- Check browser console SSE connection status
- Confirm training process has started and is writing log files
- System will automatically fallback to polling mode

### Inference Failed
- Confirm model weight file `best.pt` exists
- Check if uploaded image format is supported
- Confirm model training is complete

### Annotation Task Creation Failed
**Error**: `Image directory not found in dataset xxx`

**Solution**:
1. Return to dataset page
2. Find corresponding dataset
3. Confirm status is `prepared` not `uploaded`
4. If `uploaded`, click "Prepare Dataset" button for that dataset
5. Wait for preparation to complete before creating annotation task

### GPU Related Issues
- **CUDA out of memory**: Reduce batch size or image size
- **Low GPU utilization**: Check dataset size, ensure using disk cache
- **GPU not available**: Confirm NVIDIA drivers and NVIDIA Container Toolkit are installed

---

## ğŸ“š Related Documentation

- [Quick Start Guide](QUICK_START.md) - Detailed quick start tutorial
- [Training Optimization Guide](TRAINING_OPTIMIZATION.md) - Training performance optimization details

---

## ğŸ“„ License

MIT
